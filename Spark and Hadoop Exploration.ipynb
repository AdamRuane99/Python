{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Spark and HAdoop - RDD Transformations and Actions\n",
    "\n",
    "Here I have set up an AWS free Tier account where by connected to a linux instance from my windows machine using PuTTy. \n",
    "I set up the EC2 instance and configured the security groups setting for these spot instances and I kept all the ports open for simplicity.\n",
    "\n",
    "There were alot of resources online to take me throigh this set up process\n",
    "\n",
    "I then Converted my private key using PuTTYgen and using the AWS User guide for LInux instances for guidance. \n",
    "\n",
    "I was then able to connect using my instance's public DNS name.\n",
    "\n",
    "Once I was in my virtual machine I Downloaded and Installed Anaconda at the command line.\n",
    "\n",
    "Using code such as below: \n",
    "\n",
    "$ which python\n",
    "\n",
    "In order to change:\n",
    "$ source .bashrc\n",
    "\n",
    "$ jupyter notebook --generate-config\n",
    "And craete a certification: \n",
    "$ mkdir certs\n",
    "$ cd certs\n",
    "$ sudo openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout mycert.pem -out mycert.pem.\n",
    "\n",
    "\n",
    "Afet this I could edit the file : \n",
    "$ cd ~/.jupyter/\n",
    "$ vi jupyter_notebook_config.py\n",
    "\n",
    "\n",
    "I was then able to get mu jupyter notebook linked to my instance. \n",
    "c = get_config()\n",
    "\n",
    "Notebook config this is where you saved your pem cert\n",
    "c.NotebookApp.certfile = u'/home/ubuntu/certs/mycert.pem' \n",
    "Run on all IP addresses of your instance\n",
    "c.NotebookApp.ip = '*'\n",
    "Don't open browser by default\n",
    "c.NotebookApp.open_browser = False  \n",
    "Fix port to 8888\n",
    "c.NotebookApp.port = 8888\n",
    "\n",
    "$ jupyter notebook\n",
    "\n",
    "I then had to install Java in order to install Scala, which I need for Spark. Back at my EC2 command line I did so. \n",
    "\n",
    "\n",
    "Installing Spark and Hadoop: \n",
    "$ wget http://archive.apache.org/dist/spark/spark-2.0.0/spark-2.0.0-bin-hadoop2.7.tgz\n",
    "$ sudo tar -zxvf spark-2.0.0-bin-hadoop2.7.tgz\n",
    "\n",
    "\n",
    "After this I directed it towards my notebook:\n",
    "$ export SPARK_HOME='/home/ubuntu/spark-2.0.0-bin-hadoop2.7'\n",
    "$ export PATH=$SPARK_HOME:$PATH\n",
    "$ export PYTHONPATH=$SPARK_HOME/python:$PYTHONPATH\n",
    "\n",
    "Once this was all done I could work in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Creating an RDD from a text file:\n",
    "\n",
    "** Creating the textfile **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile example2.txt\n",
    "first \n",
    "second line\n",
    "the third line\n",
    "then a fourth line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing some transformations and actions on this text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show RDD\n",
    "sc.textFile('example2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save a reference to this RDD\n",
    "text_rdd = sc.textFile('example2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['first'],\n",
       " ['second', 'line'],\n",
       " ['the', 'third', 'line'],\n",
       " ['then', 'a', 'fourth', 'line']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map a function (or lambda expression) to each line\n",
    "# Then collect the results.\n",
    "text_rdd.map(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map vs flatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'second',\n",
       " 'line',\n",
       " 'the',\n",
       " 'third',\n",
       " 'line',\n",
       " 'then',\n",
       " 'a',\n",
       " 'fourth',\n",
       " 'line']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect everything as a single flat map\n",
    "text_rdd.flatMap(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDDs and Key Value Pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing services.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile services.txt\n",
    "#EventId    Timestamp    Customer   State    ServiceID    Amount\n",
    "201       10/13/2017      100       NY       131          100.00\n",
    "204       10/18/2017      700       TX       129          450.00\n",
    "202       10/15/2017      203       CA       121          200.00\n",
    "206       10/19/2017      202       CA       131          500.00\n",
    "203       10/17/2017      101       NY       173          750.00\n",
    "205       10/19/2017      202       TX       121          200.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "services = sc.textFile('services.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#EventId    Timestamp    Customer   State    ServiceID    Amount',\n",
       " '201       10/13/2017      100       NY       131          100.00']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[10] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#EventId', 'Timestamp', 'Customer', 'State', 'ServiceID', 'Amount'],\n",
       " ['201', '10/13/2017', '100', 'NY', '131', '100.00'],\n",
       " ['204', '10/18/2017', '700', 'TX', '129', '450.00']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda x: x.split()).take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing that first hash-tag!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EventId    Timestamp    Customer   State    ServiceID    Amount',\n",
       " '201       10/13/2017      100       NY       131          100.00',\n",
       " '204       10/18/2017      700       TX       129          450.00',\n",
       " '202       10/15/2017      203       CA       121          200.00',\n",
       " '206       10/19/2017      202       CA       131          500.00',\n",
       " '203       10/17/2017      101       NY       173          750.00',\n",
       " '205       10/19/2017      202       TX       121          200.00']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda x: x[1:] if x[0]=='#' else x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EventId', 'Timestamp', 'Customer', 'State', 'ServiceID', 'Amount'],\n",
       " ['201', '10/13/2017', '100', 'NY', '131', '100.00'],\n",
       " ['204', '10/18/2017', '700', 'TX', '129', '450.00'],\n",
       " ['202', '10/15/2017', '203', 'CA', '121', '200.00'],\n",
       " ['206', '10/19/2017', '202', 'CA', '131', '500.00'],\n",
       " ['203', '10/17/2017', '101', 'NY', '173', '750.00'],\n",
       " ['205', '10/19/2017', '202', 'TX', '121', '200.00']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda x: x[1:] if x[0]=='#' else x).map(lambda x: x.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Key Value Pairs for Operations\n",
    "\n",
    "Using methods that combine lambda expressions that use a ByKey argument. These ByKey methods will assume that the data is in a Key,Value form. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From Previous\n",
    "cleanServ = services.map(lambda x: x[1:] if x[0]=='#' else x).map(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EventId', 'Timestamp', 'Customer', 'State', 'ServiceID', 'Amount'],\n",
       " ['201', '10/13/2017', '100', 'NY', '131', '100.00'],\n",
       " ['204', '10/18/2017', '700', 'TX', '129', '450.00'],\n",
       " ['202', '10/15/2017', '203', 'CA', '121', '200.00'],\n",
       " ['206', '10/19/2017', '202', 'CA', '131', '500.00'],\n",
       " ['203', '10/17/2017', '101', 'NY', '173', '750.00'],\n",
       " ['205', '10/19/2017', '202', 'TX', '121', '200.00']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanServ.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('State', 'Amount'),\n",
       " ('NY', '100.00'),\n",
       " ('TX', '450.00'),\n",
       " ('CA', '200.00'),\n",
       " ('CA', '500.00'),\n",
       " ('NY', '750.00'),\n",
       " ('TX', '200.00')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start by practicing grabbing fields\n",
    "cleanServ.map(lambda lst: (lst[3],lst[-1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('State', 'Amount'),\n",
       " ('NY', '100.00750.00'),\n",
       " ('TX', '450.00200.00'),\n",
       " ('CA', '200.00500.00')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue with reduceByKey\n",
    "# Notice how it assumes that the first item is the key!\n",
    "cleanServ.map(lambda lst: (lst[3],lst[-1]))\\\n",
    "         .reduceByKey(lambda amt1,amt2 : amt1+amt2)\\\n",
    "         .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Floats!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('State', 'Amount'), ('NY', 850.0), ('TX', 650.0), ('CA', 700.0)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue with reduceByKey\n",
    "# Notice how it assumes that the first item is the key!\n",
    "cleanServ.map(lambda lst: (lst[3],lst[-1]))\\\n",
    "         .reduceByKey(lambda amt1,amt2 : float(amt1)+float(amt2))\\\n",
    "         .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NY', 850.0), ('CA', 700.0), ('TX', 650.0)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab state and amounts\n",
    "# Add them\n",
    "# Get rid of ('State','Amount')\n",
    "# Sort them by the amount value\n",
    "cleanServ.map(lambda lst: (lst[3],lst[-1]))\\\n",
    ".reduceByKey(lambda amt1,amt2 : float(amt1)+float(amt2))\\\n",
    ".filter(lambda x: not x[0]=='State')\\\n",
    ".sortBy(lambda stateAmount: stateAmount[1], ascending=False)\\\n",
    ".collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
